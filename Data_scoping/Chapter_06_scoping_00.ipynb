{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python version is 3.8.2 (default, Mar 26 2020, 10:43:30) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)].\n",
      "\n",
      "The Numpy version is 1.19.2.\n",
      "\n",
      "The Pandas version is 1.2.1.\n",
      "\n",
      "The Matplotlib version is 3.3.2.\n",
      "\n",
      "The Graphviz version is 0.15.\n",
      "\n",
      "The Scikit-Learn version is 0.23.2.\n",
      "\n",
      "The XGBoost version is 1.3.0.\n",
      "\n",
      "The Shap version is 0.37.0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load packages and check versions\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 400 #high res figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphviz\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "print('The Python version is {}.\\n'.format(sys.version))\n",
    "print('The Numpy version is {}.\\n'.format(np.__version__))\n",
    "print('The Pandas version is {}.\\n'.format(pd.__version__))\n",
    "print('The Matplotlib version is {}.\\n'.format(mpl.__version__))\n",
    "print('The Graphviz version is {}.\\n'.format(graphviz.__version__))\n",
    "print('The Scikit-Learn version is {}.\\n'.format(sklearn.__version__))\n",
    "print('The XGBoost version is {}.\\n'.format(xgb.__version__))\n",
    "print('The Shap version is {}.\\n'.format(shap.__version__))\n",
    "# The Python version is 3.8.2 (default, Mar 26 2020, 10:43:30) \n",
    "# [Clang 4.0.1 (tags/RELEASE_401/final)].\n",
    "\n",
    "# The Numpy version is 1.19.2.\n",
    "\n",
    "# The Pandas version is 1.2.1.\n",
    "\n",
    "# The Matplotlib version is 3.3.2.\n",
    "\n",
    "# The Graphviz version is 0.15.\n",
    "\n",
    "# The Scikit-Learn version is 0.23.2.\n",
    "\n",
    "# The XGBoost version is 1.3.0.\n",
    "\n",
    "# The Shap version is 0.37.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe do an example on synthetic dataset (or some other real data from the UCI repository), as the illustration for the chapter, before this which would probably be the Activity. How to introduce the idea of early stopping? This seems somewhat complicated to combine with the 4 fold CV splits I've been using to compare different approaches. Maybe I could do it in the chapter but then not in the activity.\n",
    "\n",
    "Docs for python: https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
    "\n",
    "Maybe also worth paying attention to:\n",
    "https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "\n",
    "---\n",
    "Goals:\n",
    "\n",
    "- Figure out how to correctly use the `grow_policy` paramter to experiment with the `lossguide` policy. I think I need to set the `tree_method` based on this, so will need to understand that hyperparameter as well. Described here and good to read through this thoroughly: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "- Is there some way to set the response variable fraction so it doesn't assume 0.5? I remember John talking about this at some point... probably good to ask him. Maybe good in general to ask him about these two goals in our 1-1 as I think I initially heard about both options from him.\n",
    "\n",
    "\n",
    "Do I include all hyperparameter options in the book? I did this in the first edition and going through for the second edition it seems kind of like a waste of space... I'm wondering what the value add is above having readers just look at the website documentation. May want to go back and delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Chapter_1_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_response = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_remove = ['ID', 'SEX', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                   'EDUCATION_CAT', 'graduate school', 'high school', 'none',\n",
    "                   'others', 'university']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMIT_BAL',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_1',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'default payment next month']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_response = [item for item in features_response if item not in items_to_remove]\n",
    "features_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df[features_response[:-1]].values,\n",
    "                 df['default payment next month'].values,\n",
    "                 test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     max_depth=3,\n",
    "#     learning_rate=0.01,\n",
    "#     verbosity=1,\n",
    "#     objective='binary:logistic',\n",
    "#     use_label_encoder=False,\n",
    "#     n_jobs=-1,\n",
    "#     min_child_weight=100)\n",
    "# params = {'max_depth':[6],\n",
    "#           'n_estimators':[1000],\n",
    "#           'colsample_bytree':[0.9],\n",
    "#           'subsample':[0.9]}\n",
    "# #Above can beat the RF in the 4-fold CV\n",
    "# # 0.777226\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=0,\n",
    "    max_leaves=100,\n",
    "    learning_rate=0.01,\n",
    "    verbosity=1,\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1,\n",
    "    min_child_weight=100,\n",
    "    tree_method='hist',\n",
    "    grow_policy='lossguide')\n",
    "params = {'n_estimators':[1000],\n",
    "          'colsample_bytree':[0.9],\n",
    "          'subsample':[0.9]}\n",
    "# 0.777415 so comparable, and works a lot faster than the above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb = GridSearchCV(xgb_model, param_grid=params, scoring='roc_auc',\n",
    "                  n_jobs=None, refit=True, cv=4, verbose=1,\n",
    "                  pre_dispatch=None, error_score=np.nan,\n",
    "                  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[13:34:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 1min 12s, sys: 2.1 s, total: 1min 14s\n",
      "Wall time: 22.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy='lossguide',\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.01, max_delta_step=None,\n",
       "                                     max_depth=0, max_leaves=100,\n",
       "                                     min_child_weight=100, missing=nan,\n",
       "                                     monotone_const...\n",
       "                                     n_estimators=1000, n_jobs=-1,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method='hist',\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=1),\n",
       "             param_grid={'colsample_bytree': [0.9], 'n_estimators': [1000],\n",
       "                         'subsample': [0.9]},\n",
       "             pre_dispatch=None, return_train_score=True, scoring='roc_auc',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cv_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_results_df = pd.DataFrame(cv_xgb.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.026787</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.071355</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'n_estimators': 1000...</td>\n",
       "      <td>0.771406</td>\n",
       "      <td>0.769602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.777415</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.824991</td>\n",
       "      <td>0.827054</td>\n",
       "      <td>0.82156</td>\n",
       "      <td>0.825088</td>\n",
       "      <td>0.824673</td>\n",
       "      <td>0.001977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.026787      0.111627         0.071355        0.001617   \n",
       "\n",
       "  param_colsample_bytree param_n_estimators param_subsample  \\\n",
       "0                    0.9               1000             0.9   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'colsample_bytree': 0.9, 'n_estimators': 1000...           0.771406   \n",
       "\n",
       "   split1_test_score  ...  split3_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.769602  ...           0.778443         0.777415        0.008091   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.824991            0.827054   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0             0.82156            0.825088          0.824673         0.001977  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Model type not yet supported by TreeExplainer: <class 'sklearn.model_selection._search.GridSearchCV'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dspwp2/lib/python3.8/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, **deprecated_options)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_perturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dspwp2/lib/python3.8/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model type not yet supported by TreeExplainer: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# build a dense numpy version of all the tree objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Model type not yet supported by TreeExplainer: <class 'sklearn.model_selection._search.GridSearchCV'>"
     ]
    }
   ],
   "source": [
    "%time explainer = shap.TreeExplainer(cv_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
